{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute if necessary\n",
    "# %%capture\n",
    "# !pip install numpy seaborn matplotlib pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from typing import Dict, Tuple, Union, List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 3: Modelo Lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Instrucciones__: A continuación hay una lista de funciones que debe implementar o tareas que debe desarrollar. La descripción de cada una de ellas se encuentra en la definición de cada una de las funciones. Cada función está marcada por &#x1F625;,  &#x1F643; o &#x1F921;. Las marcas indican:\n",
    "\n",
    "- &#x1F625;: Indican una entrega que debe ser hecha dentro de la misma sesión de la asignación. \n",
    "- &#x1F643;: Indican una entrega que puede ser hecha hasta la siguiente sesión.\n",
    "- &#x1F921;: Debe mostrar un avance en la misma sesión, pero la entrega puede ser hecha en la siguiente.\n",
    "\n",
    "Aquellas entregas parciales que no sean hechas el día de la asignación ya no serán válidas para las entregas totales, sin embargo, las entregas totales seguirán siendo válidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se incluye un dataset real. El dataset importado incluye multiples características que describen las condiciones de los pasajeros en el accidente del titanic.\n",
    "\n",
    "- __PassengerId__: Identificador de cada pasajero.\n",
    "- __Survived__: 0 si no sobrevivió al accidente, 1 si lo hizo.\n",
    "- __Pclass__: Clase en la que viajaba el pasajero, 1 - Primera clase, 2 - Segunda clase y 3 - Tercera clase.\n",
    "- __Name__: Nombre del pasajero.\n",
    "- __Sex__: Sexo del pasajero.\n",
    "- __Age__: Edad del pasajero.\n",
    "- __SibSp__: Número de hermanos más número de esposas con las que viajaba el pasajero.\n",
    "- __Parch__: Número de padres más número de hijos con las que viajaba el pasajero.\n",
    "- __Ticket__: Número de boleto.\n",
    "- __Fare__: Tarifa del boleto del pasajero.\n",
    "- __Cabin__: Número de cabina del pasajero.\n",
    "- __Embarked__: Puerto de embarcación, C - Cherbourg, Q - Queenstown y S - Southampton.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"titanic (1).csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asignación 1 &#x1F625;\n",
    "\n",
    "Realice el preprocesamiento que considere adecuado para que las características __Pclass__, __Sex__, __SibSp__, __Parch__, __Fare__, __Cabin__, __Embarked__ y __Survived__ puedan ser utilizadas por un modelo lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Tuple, Union, List\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importar dataframe\n",
    "df = pd.read_csv(\"titanic (1).csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0         0       3    male  22.0      1      0   7.2500        S\n",
       "1         1       1  female  38.0      1      0  71.2833        C\n",
       "2         1       3  female  26.0      0      0   7.9250        S"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#realizar preprocesamiento de datos\n",
    "#eliminar columnas que no aportan informacion\n",
    "\n",
    "df = df.drop(columns=[\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"])\n",
    "df.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminar filas con valores nulos \n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminar la columna de embarque\n",
    "df = df.drop(columns=[\"Embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#preprocesar los datos de Sex y Embarked para que sean numericos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "categorical_vars = [\"Sex\"]\n",
    "one_hot_encoder = OneHotEncoder(sparse=False, drop = \"first\")\n",
    "\n",
    "# aplicar la logica del one hot encoder a las variables categoricas\n",
    "encoder_vars_array = one_hot_encoder.fit_transform(df[categorical_vars])\n",
    "\n",
    "# crear un objeto para los nombres de las variables usando las variables categoricas\n",
    "encoder_feature_names = one_hot_encoder.get_feature_names_out(categorical_vars)\n",
    "\n",
    "# crear un dataframe para guardar las variables codificadas\n",
    "encoder_vars_df = pd.DataFrame(encoder_vars_array, columns = encoder_feature_names)\n",
    "\n",
    "# concatenar el nuevo dataframe con las variables codificadas al dataframe original\n",
    "X_new = pd.concat([df.reset_index(drop=True), encoder_vars_df.reset_index(drop=True)], axis = 1)\n",
    "\n",
    "# eliminar las variables categoricas del dataframe original\n",
    "X_new.drop(categorical_vars, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age  SibSp  Parch     Fare  Sex_male\n",
       "0         0       3  22.0      1      0   7.2500       1.0\n",
       "1         1       1  38.0      1      0  71.2833       0.0\n",
       "2         1       3  26.0      0      0   7.9250       0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué se necesita para realizar una regresión lineal?\n",
    "1. Una variable dependiente y una variable independiente\n",
    "2. Una relación lineal entre las variables\n",
    "3. Que los datos sean continuos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asignación 2 &#x1F625;\n",
    "\n",
    "Utilizando las características __Pclass__, __Sex__, __SibSp__, __Parch__, __Fare__, __Cabin__ y __Embarked__, entrene un clasificador lineal para predecir __Survived__ utilizando el algoritmo _pocket_. Imprima el error obtenido."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uitilizando una Regresion Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precicion del modelo:  0.7902097902097902\n",
      "Probabilidad de supervivencia:  0.9438468687689205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#entrenar un clasificador lineal para predecir la supervivencia de los pasajeros\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#eliminar los na de X_new\n",
    "X_new = X_new.dropna()\n",
    "X_new2 = X_new\n",
    "\n",
    "#separar los datos en variables independientes y dependientes\n",
    "X = X_new.drop(columns=[\"Survived\"])\n",
    "y = X_new[\"Survived\"]\n",
    "\n",
    "#separar los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#entrenar el modelo\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#evaluar el modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "#realizar predicciones\n",
    "#crear un dataframe con los datos de un pasajero\n",
    "new_passenger = pd.DataFrame({\n",
    "    \"Pclass\": [1],\n",
    "    \"Age\": [22],\n",
    "    \"SibSp\": [1],\n",
    "    \"Parch\": [0],\n",
    "    \"Fare\": [7.25],\n",
    "    \"Sex_male\": [0.0],\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "print(\"Precicion del modelo: \", accuracy_score(y_test, y_pred))\n",
    "#predecir la probabilidad de supervivencia del pasajero\n",
    "print(\"Probabilidad de supervivencia: \", model.predict_proba(new_passenger)[0][1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  0.3560126582278481\n",
      "Accuracy:  0.6439873417721519\n",
      "Predicted values:  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Actual values:  [1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1.\n",
      " 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1.\n",
      " 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.\n",
      " 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1.\n",
      " 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1.\n",
      " 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0.\n",
      " 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1.\n",
      " 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1.\n",
      " 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0.\n",
      " 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1.\n",
      " 0. 1. 1. 0. 1. 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "import pandas as pd\n",
    "\n",
    "df = X_new\n",
    "\n",
    "X_train = df.iloc[:80,:-1]\n",
    "y_train = df.iloc[:80,-1]\n",
    "X_test = df.iloc[80:,:-1]\n",
    "y_test = df.iloc[80:,-1]\n",
    "\n",
    "# Initialize the Pocket Algorithm\n",
    "pocket = Perceptron(max_iter=1000)\n",
    "\n",
    "# Fit the model to the training data\n",
    "pocket.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target values for the test data\n",
    "y_pred = pocket.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('Mean Squared Error: ', mse)\n",
    "print('Accuracy: ', 1 - mse)\n",
    "print('Predicted values: ', y_pred)\n",
    "print('Actual values: ', y_test.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age  SibSp  Parch     Fare  Sex_male\n",
       "0       3  22.0      1      0   7.2500       1.0\n",
       "1       1  38.0      1      0  71.2833       0.0\n",
       "2       3  26.0      0      0   7.9250       0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#eliminar los na de X_new\n",
    "X_new2 = X_new.dropna()\n",
    "\n",
    "#separar los datos en variables independientes y dependientes\n",
    "X = X_new2.drop(columns=[\"Survived\"])\n",
    "y = X_new2[\"Survived\"]\n",
    "\n",
    "X.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando algoritmo Pocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  0.6901408450704225\n",
      "Accuracy:  0.3098591549295775\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "#Eliminar survival de X_new2\n",
    "dfY = X_new2[\"Survived\"]\n",
    "dfX = X_new2.drop(columns=[\"Survived\"])\n",
    "\n",
    "#separar los datos en entrenamiento y prueba\n",
    "X_train = X_new2.iloc[:570,1:].values\n",
    "y_train = X_new2.iloc[:570,:1].values\n",
    "X_test = X_new2.iloc[:142,1:].values\n",
    "y_test = X_new2.iloc[:142,:1].values\n",
    "\n",
    "\n",
    "# Inicializar el algoritmo de Pocket\n",
    "w = np.zeros(X_train.shape[1])\n",
    "w_pocket = np.zeros(X_train.shape[1])\n",
    "T = 5000\n",
    "err_pocket = np.inf\n",
    "\n",
    "# Ajustar el modelo a los datos de entrenamiento\n",
    "for t in range(T):\n",
    "    \n",
    "    # Seleccionar un ejemplo de entrenamiento aleatorio\n",
    "    i = np.random.randint(X_train.shape[0])\n",
    "    xi = X_train[i,:]\n",
    "    yi = y_train[i]\n",
    "    \n",
    "\n",
    "    # Computar el valor de la variable objetivo predicha\n",
    "    yi_hat = np.sign(np.dot(w, xi))\n",
    "    \n",
    "\n",
    "    # Actualizar el vector de pesos\n",
    "    if yi_hat != yi:\n",
    "        w = w + yi * xi\n",
    "        \n",
    "        \n",
    "        # Evaluar el rendimiento del vector de pesos actualizado\n",
    "        y_pred = np.sign(np.dot(X_train, w))\n",
    "        err = np.sum(y_pred != y_train) / y_train.shape[0]\n",
    "        \n",
    "       \n",
    "        # Revisar si el vector de pesos actualizado es mejor que el vector de pesos de la bolsa\n",
    "        if err < err_pocket:\n",
    "            err_pocket = err\n",
    "            w_pocket = np.copy(w)\n",
    "\n",
    "# Predecir los valores de la variable objetivo para los datos de prueba\n",
    "y_pred = np.sign(np.dot(X_test, w_pocket))\n",
    "\n",
    "# Evaluar el rendimiento del modelo\n",
    "mse = np.mean((y_test - y_pred)**2)\n",
    "print('Mean Squared Error: ', mse)\n",
    "print('Accuracy: ', 1 - mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asignación 3 &#x1F625;\n",
    "\n",
    "Utilizando las características __Pclass__, __Sex__, __SibSp__, __Parch__, __Cabin__ y __Embarked__, entrene una regresión lineal para predecir __Fare__ utilizando el algoritmo de Ordinary Leasts Squares (OLS). Imprima el valor del error cuadrático medio (MSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  SibSp  Parch     Fare  Embarked_Q  Embarked_S\n",
       "0       3      1      0   7.2500         0.0         1.0\n",
       "1       1      1      0  71.2833         0.0         0.0\n",
       "2       3      0      0   7.9250         0.0         1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importar titanic (1).csv a una variable llamada df\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"titanic (1).csv\")\n",
    "\n",
    "# eliminar las columnas PassengerId, Name, Ticket y Cabin\n",
    "df = df.drop(columns=[\"PassengerId\", \"Name\", \"Ticket\", \"Sex\",\"Survived\",\"Age\",\"Cabin\"])\n",
    "\n",
    "# eliminar las filas con valores nulos\n",
    "df = df.dropna()\n",
    "\n",
    "df\n",
    "\n",
    "# utilizar oneHotEncoding para embarked y Sex \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "categorical_vars = [\"Embarked\"]\n",
    "one_hot_encoder = OneHotEncoder(sparse=False, drop = \"first\")\n",
    "\n",
    "# aplicar la logica del one hot encoder a las variables categoricas\n",
    "encoder_vars_array = one_hot_encoder.fit_transform(df[categorical_vars])\n",
    "\n",
    "# crear un objeto para los nombres de las variables usando las variables categoricas\n",
    "encoder_feature_names = one_hot_encoder.get_feature_names_out(categorical_vars)\n",
    "\n",
    "# crear un dataframe para guardar las variables codificadas\n",
    "encoder_vars_df = pd.DataFrame(encoder_vars_array, columns = encoder_feature_names)\n",
    "\n",
    "\n",
    "# concatenar el nuevo dataframe con las variables codificadas al dataframe original\n",
    "X_new = pd.concat([df.reset_index(drop=True), encoder_vars_df.reset_index(drop=True)], axis = 1)\n",
    "\n",
    "# eliminar las variables categoricas del dataframe original\n",
    "X_new.drop(categorical_vars, axis = 1, inplace = True)\n",
    "\n",
    "X_new.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminar los na de X_new\n",
    "X_new2 = X_new.dropna()\n",
    "\n",
    "#seleccionar Pclass , SibSp , Parch , Embarked_Q y Embarked_S como variables independientes\n",
    "X = X_new2[[\"Pclass\", \"SibSp\", \"Parch\", \"Embarked_Q\", \"Embarked_S\"]]\n",
    "y = X_new2[\"Fare\"]\n",
    "\n",
    "#separar los datos en entrenamiento y prueba (80% entrenamiento y 20% prueba) \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " El algoritmo de Ordinary Least Squares (OLS) es una técnica de regresión lineal que se utiliza para estimar los coeficientes de una función lineal que mejor se ajuste a un conjunto de datos. En Python, podemos implementar el algoritmo de OLS utilizando la librería NumPy para el álgebra lineal y la librería Matplotlib para graficar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  1.8829413425145808e+273\n",
      "Accuracy:  -1.8829413425145808e+273\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Inicializar los parámetros del modelo\n",
    "w = np.zeros(X_train.shape[1])\n",
    "b = 0\n",
    "alpha = 0.001\n",
    "T = 200\n",
    "\n",
    "# Ajustar el modelo a los datos de entrenamiento\n",
    "for t in range(T):\n",
    "        \n",
    "        # Computar el valor de la variable objetivo predicha\n",
    "        y_pred = np.dot(X_train, w) + b\n",
    "        \n",
    "        # Computar el error\n",
    "        error = y_train - y_pred\n",
    "        \n",
    "        # Actualizar los parámetros del modelo\n",
    "        w = w + alpha * np.dot(X_train.T, error)\n",
    "        b = b + alpha * np.sum(error)\n",
    "\n",
    "# Predecir los valores de la variable objetivo para los datos de prueba\n",
    "y_pred = np.dot(X_test, w) + b\n",
    "\n",
    "# Evaluar el rendimiento del modelo\n",
    "mse = np.mean((y_test - y_pred)**2)\n",
    "print('Mean Squared Error: ', mse*100)\n",
    "print('Accuracy: ', 1 - mse*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asignación 4 &#x1F921;\n",
    "\n",
    "Utilizando las características __Pclass__, __Sex__, __SibSp__, __Parch__, __Fare__, __Cabin__ y __Embarked__, entrene un clasificador lineal para predecir la probabilidad de supervivencia __Survived__ utilizando el algoritmo de gradiente descendente estocástico y la entropía cruzada como función de error. Imprima el arror en cada iteración del gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar los datos\n",
    "data = pd.read_csv('titanic (1).csv')\n",
    "\n",
    "# Preprocesar los datos\n",
    "data = data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1) # Eliminar variables no útiles\n",
    "data['Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0]) # Tratar valores faltantes en Embarked\n",
    "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1}) # Codificar variable categórica Sex\n",
    "\n",
    "\n",
    "# Eliminar filas con valores faltantes\n",
    "data = data.dropna()\n",
    "\n",
    "\n",
    "# Codificar variables categóricas Cabin y Embarked con one-hot encoding \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "categorical_vars = [\"Embarked\"]\n",
    "one_hot_encoder = OneHotEncoder(sparse=False, drop = \"first\")\n",
    "\n",
    "# aplicar la logica del one hot encoder a las variables categoricas\n",
    "encoder_vars_array = one_hot_encoder.fit_transform(data[categorical_vars])\n",
    "\n",
    "# crear un objeto para los nombres de las variables usando las variables categoricas\n",
    "encoder_feature_names = one_hot_encoder.get_feature_names_out(categorical_vars)\n",
    "\n",
    "# crear un dataframe para guardar las variables codificadas\n",
    "encoder_vars_df = pd.DataFrame(encoder_vars_array, columns = encoder_feature_names)\n",
    "\n",
    "\n",
    "# concatenar el nuevo dataframe con las variables codificadas al dataframe original\n",
    "data = pd.concat([data.reset_index(drop=True), encoder_vars_df.reset_index(drop=True)], axis = 1)\n",
    "\n",
    "# eliminar las variables categoricas del dataframe original\n",
    "data.drop(categorical_vars, axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "# Separar los datos en variables independientes y variable objetivo\n",
    "X = data.drop(['Survived'], axis=1)\n",
    "y = data['Survived']\n",
    "\n",
    "# Separar los datos en datos de entrenamiento y datos de prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convertir X_train y X_test a numpy array\n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "\n",
    "#convertir y_train y y_test a numpy array\n",
    "y_train = y_train.to_numpy()\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.to_numpy()\n",
    "y_test = y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(571, 8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(571, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (8,) (8,32) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m             w \u001b[39m=\u001b[39m w \u001b[39m+\u001b[39m lr \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mdot(X_batch\u001b[39m.\u001b[39mT, error)\n\u001b[1;32m     29\u001b[0m     \u001b[39mreturn\u001b[39;00m w\n\u001b[0;32m---> 31\u001b[0m sgd(X, y, lr\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[22], line 28\u001b[0m, in \u001b[0;36msgd\u001b[0;34m(X, y, lr, epochs, batch_size)\u001b[0m\n\u001b[1;32m     26\u001b[0m         error \u001b[39m=\u001b[39m y_batch \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mdot(X_batch, w)\n\u001b[1;32m     27\u001b[0m         \u001b[39m# Actualizar los pesos\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m         w \u001b[39m=\u001b[39m w \u001b[39m+\u001b[39;49m lr \u001b[39m*\u001b[39;49m np\u001b[39m.\u001b[39;49mdot(X_batch\u001b[39m.\u001b[39;49mT, error)\n\u001b[1;32m     29\u001b[0m \u001b[39mreturn\u001b[39;00m w\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (8,) (8,32) "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Cargamos los datos\n",
    "X = X_train\n",
    "y = y_train\n",
    "\n",
    "\n",
    "def sgd(X, y, lr=0.01, epochs=100, batch_size=32):\n",
    "    # Inicializar pesos aleatorios\n",
    "    w = np.random.randn(X.shape[1])\n",
    "    # Número de lotes por época\n",
    "    num_batches = X.shape[0] // batch_size\n",
    "    # Ciclo de entrenamiento\n",
    "    for epoch in range(epochs):\n",
    "        # Barajar los datos en cada época\n",
    "        permuted_idxs = np.random.permutation(X.shape[0])\n",
    "        X = X[permuted_idxs]\n",
    "        y = y[permuted_idxs]\n",
    "        # Ciclo de entrenamiento por lotes\n",
    "        for batch in range(num_batches):\n",
    "            # Seleccionar un lote de datos\n",
    "            X_batch = X[batch*batch_size:(batch+1)*batch_size]\n",
    "            y_batch = y[batch*batch_size:(batch+1)*batch_size]\n",
    "            # Calcular el error\n",
    "            error = y_batch - np.dot(X_batch, w)\n",
    "            # Actualizar los pesos\n",
    "            w = w + lr * np.dot(X_batch.T, error)\n",
    "    return w\n",
    "\n",
    "sgd(X, y, lr=0.01, epochs=100, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([129, 46], dtype='int64')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 41\u001b[0m\n\u001b[1;32m     36\u001b[0m         b \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m learning_rate \u001b[39m*\u001b[39m grad_b\n\u001b[1;32m     38\u001b[0m     \u001b[39mreturn\u001b[39;00m w, b\n\u001b[0;32m---> 41\u001b[0m w, b \u001b[39m=\u001b[39m stochastic_gradient_descent(X_train, y_train, learning_rate\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m     43\u001b[0m \u001b[39m# Hacer una predicción con el modelo entrenado\u001b[39;00m\n\u001b[1;32m     44\u001b[0m z \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(X, w) \u001b[39m+\u001b[39m b\n",
      "Cell \u001b[0;32mIn[21], line 24\u001b[0m, in \u001b[0;36mstochastic_gradient_descent\u001b[0;34m(X, y, learning_rate, epochs, batch_size)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m     22\u001b[0m     \u001b[39m# Seleccionar una muestra aleatoria del conjunto de datos\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], batch_size, replace\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> 24\u001b[0m     x_batch \u001b[39m=\u001b[39m X[idx]\n\u001b[1;32m     25\u001b[0m     y_batch \u001b[39m=\u001b[39m y[idx]\n\u001b[1;32m     27\u001b[0m     \u001b[39m# Calcular el gradiente de la función de pérdida\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3812\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3813\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3815\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexes/base.py:6130\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6128\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   6129\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 6130\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m   6133\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([129, 46], dtype='int64')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Definir la función sigmoide\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Definir la función de pérdida de entropía cruzada\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    epsilon = 1e-5\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    return -(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "# Definir el algoritmo de gradiente descendente estocástico\n",
    "def stochastic_gradient_descent(X, y, learning_rate=0.01, epochs=100, batch_size=32):\n",
    "    # Inicializar los pesos y el sesgo\n",
    "    n_features = X.shape[1]\n",
    "    w = np.zeros(n_features)\n",
    "    b = 0\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    for i in range(epochs):\n",
    "        # Seleccionar una muestra aleatoria del conjunto de datos\n",
    "        idx = np.random.choice(X.shape[0], batch_size, replace=False)\n",
    "        x_batch = X[idx]\n",
    "        y_batch = y[idx]\n",
    "\n",
    "        # Calcular el gradiente de la función de pérdida\n",
    "        z = np.dot(x_batch, w) + b\n",
    "        y_pred = sigmoid(z)\n",
    "        error = y_batch - y_pred\n",
    "        grad_w = -np.dot(x_batch.T, error) / batch_size\n",
    "        grad_b = -np.mean(error)\n",
    "\n",
    "        # Actualizar los pesos y el sesgo\n",
    "        w -= learning_rate * grad_w\n",
    "        b -= learning_rate * grad_b\n",
    "\n",
    "    return w, b\n",
    "\n",
    "\n",
    "w, b = stochastic_gradient_descent(X_train, y_train, learning_rate=0.1, epochs=1000, batch_size=2)\n",
    "\n",
    "# Hacer una predicción con el modelo entrenado\n",
    "z = np.dot(X, w) + b\n",
    "y_pred = sigmoid(z)\n",
    "print(y_pred)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
